import base64
import io
import os
import struct
import threading
import time
from collections import defaultdict
from datetime import datetime

import matplotlib
import matplotlib.pyplot as plt
import mne
import numpy as np
import pika
import zstandard
from flask import Flask, jsonify
from mne_connectivity import spectral_connectivity_epochs
from mne_connectivity.viz import plot_connectivity_circle

# MatplotlibãŒGUIã®ãªã„ã‚µãƒ¼ãƒãƒ¼ç’°å¢ƒã§å‹•ä½œã™ã‚‹ãŸã‚ã®è¨­å®š
matplotlib.use("Agg")

# --- Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° ---
app = Flask(__name__)
latest_analysis_results = defaultdict(dict)
user_data_buffers = defaultdict(lambda: np.array([]))
analysis_lock = threading.Lock()
buffer_lock = threading.Lock()

# --- å®šæ•°ã¨è¨­å®š (ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—) ---
RABBITMQ_URL = os.getenv("RABBITMQ_URL", "amqp://guest:guest@rabbitmq:5672")
SAMPLE_RATE = int(os.getenv("SAMPLE_RATE", "256"))
NUM_EEG_CHANNELS = 8
ANALYSIS_WINDOW_SEC = 2.0
ANALYSIS_WINDOW_SAMPLES = int(SAMPLE_RATE * ANALYSIS_WINDOW_SEC)
CHANNEL_NAMES = ["Fp1", "Fp2", "F7", "F8", "T7", "T8", "P7", "P8"]

# MNEãƒ©ã‚¤ãƒ–ãƒ©ãƒªç”¨ã®æƒ…å ±ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’äº‹å‰ã«ä½œæˆ
mne_info = mne.create_info(ch_names=CHANNEL_NAMES, sfreq=SAMPLE_RATE, ch_types="eeg")
try:
    mne_info.set_montage("standard_1020", on_missing="warn")
except Exception as e:
    print(f"è­¦å‘Š: é›»æ¥µä½ç½®(Montage)ã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {e}")

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
def fig_to_base64(fig):
    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight", pad_inches=0.1)
    plt.close(fig)
    buf.seek(0)
    return base64.b64encode(buf.getvalue()).decode("utf-8")

# --- ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰ ---
def analysis_worker():
    """
    ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®šæœŸçš„ã«å®Ÿè¡Œã•ã‚Œã€å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰è„³æ³¢è§£æã‚’è¡Œã„ã¾ã™ã€‚
    """
    global latest_analysis_results
    print("âœ… è§£æãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ãŒèµ·å‹•ã—ã¾ã—ãŸã€‚")
    while True:
        time.sleep(10)
        with buffer_lock:
            current_buffers = dict(user_data_buffers)
        for user_id, buffer in current_buffers.items():
            if buffer.shape[0] < ANALYSIS_WINDOW_SAMPLES:
                continue
            data_chunk = buffer[-ANALYSIS_WINDOW_SAMPLES:, :]
            try:
                # å˜ä½ã‚’[V]ã«å¤‰æ›
                data_in_volts = (data_chunk.T.astype(np.float64) - 2048.0) * (4.5 / 4096.0) * 1e-6
                raw = mne.io.RawArray(data_in_volts, mne_info, verbose=False)

                # 1. PSD (ãƒ‘ãƒ¯ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ«å¯†åº¦) ã®è¨ˆç®—ã¨æç”»
                fig_psd = raw.compute_psd(fmin=1, fmax=45, n_fft=SAMPLE_RATE, verbose=False).plot(
                    show=False, spatial_colors=True
                )
                psd_b64 = fig_to_base64(fig_psd)

                # 2. Coherence (ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹) ã®è¨ˆç®—ã¨æç”»
                epochs = mne.make_fixed_length_epochs(
                    raw, duration=ANALYSIS_WINDOW_SEC, preload=True, verbose=False
                )
                con = spectral_connectivity_epochs(
                    epochs, method="coh", sfreq=SAMPLE_RATE, fmin=8, fmax=13, faverage=True, verbose=False
                )
                
                # <<< ä¿®æ­£ç‚¹ >>>
                # get_data()ã¯(1, 8, 8)ã®3Dé…åˆ—ã‚’è¿”ã™ãŸã‚ã€squeeze()ã§(8, 8)ã®2Dé…åˆ—ã«å¤‰æ›ã™ã‚‹
                con_matrix = np.squeeze(con.get_data(output="dense"))
                
                fig_coh, _ = plot_connectivity_circle(
                    con_matrix, CHANNEL_NAMES, show=False, vmin=0, vmax=1
                )
                coh_b64 = fig_to_base64(fig_coh)

                # çµæœã‚’ä¿å­˜
                with analysis_lock:
                    latest_analysis_results[user_id] = {
                        "psd_image": psd_b64,
                        "coherence_image": coh_b64,
                        "timestamp": datetime.now().isoformat(),
                    }
                print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ãƒ¦ãƒ¼ã‚¶ãƒ¼({user_id})ã®è§£æçµæœã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")
            except Exception as e:
                print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼({user_id})ã®è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def rabbitmq_consumer():
    """
    RabbitMQã‹ã‚‰åœ§ç¸®ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’å—ä¿¡ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ ã—ã¾ã™ã€‚
    """
    global user_data_buffers
    zstd_decompressor = zstandard.ZstdDecompressor()
    # â—æ³¨æ„: ä»¥ä¸‹ã®å®šæ•°ã¯ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡ã™ã‚‹å´ã®å®Ÿè£…ã¨ä¸€è‡´ã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
    # ã‚‚ã—ä¸€è‡´ã—ã¦ã„ãªã„å ´åˆã€"Data corruption"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã™ã€‚
    HEADER_SIZE = 18
    POINT_SIZE = 53
    while True:
        try:
            connection = pika.BlockingConnection(pika.URLParameters(RABBITMQ_URL))
            channel = connection.channel()
            channel.exchange_declare(exchange="raw_data_exchange", exchange_type="fanout", durable=True)
            result = channel.queue_declare(queue="", exclusive=True)
            queue_name = result.method.queue
            channel.queue_bind(exchange="raw_data_exchange", queue=queue_name)
            def callback(ch, method, properties, body):
                global user_data_buffers
                try:
                    if not properties.headers or 'user_id' not in properties.headers:
                        print("è­¦å‘Š: user_idãŒãƒ˜ãƒƒãƒ€ãƒ¼ã«å«ã¾ã‚Œã¦ã„ãªã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç ´æ£„ã—ã¾ã—ãŸã€‚")
                        ch.basic_ack(delivery_tag=method.delivery_tag)
                        return
                    user_id = properties.headers['user_id']
                    
                    # ãƒ‡ãƒ¼ã‚¿ã‚’è§£å‡
                    decompressed_data = zstd_decompressor.decompress(body)

                    # --- ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®è§£é‡ˆ ---
                    num_points = (len(decompressed_data) - HEADER_SIZE) // POINT_SIZE
                    if num_points <= 0:
                        ch.basic_ack(delivery_tag=method.delivery_tag)
                        return
                    eeg_samples = []
                    for i in range(num_points):
                        offset = HEADER_SIZE + (i * POINT_SIZE)
                        # '<' ã¯ãƒªãƒˆãƒ«ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³, 'H' ã¯ç¬¦å·ãªã—short (2ãƒã‚¤ãƒˆ)
                        eeg_point = struct.unpack_from('<' + 'H' * NUM_EEG_CHANNELS, decompressed_data, offset)
                        eeg_samples.append(eeg_point)
                    new_samples = np.array(eeg_samples, dtype=np.uint16)
                    # -------------------------

                    # ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¯ã®ãƒãƒƒãƒ•ã‚¡ã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                    with buffer_lock:
                        current_buffer = user_data_buffers[user_id]
                        if current_buffer.size == 0:
                            user_data_buffers[user_id] = new_samples
                        else:
                            user_data_buffers[user_id] = np.vstack([current_buffer, new_samples])
                        
                        # ãƒãƒƒãƒ•ã‚¡ãŒå¤§ãããªã‚Šã™ããªã„ã‚ˆã†ã«åˆ¶å¾¡ (60ç§’åˆ†)
                        max_buffer_size = SAMPLE_RATE * 60
                        if user_data_buffers[user_id].shape[0] > max_buffer_size:
                            user_data_buffers[user_id] = user_data_buffers[user_id][-max_buffer_size:, :]
                    
                    ch.basic_ack(delivery_tag=method.delivery_tag)
                except zstandard.ZstdError as e:
                    print(f"RabbitMQã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§Zstandardè§£å‡ã‚¨ãƒ©ãƒ¼: {e}ã€‚é€ä¿¡ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    ch.basic_ack(delivery_tag=method.delivery_tag) # ã‚¨ãƒ©ãƒ¼ã§ã‚‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ACKã™ã‚‹
                except Exception as e:
                    print(f"RabbitMQã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
                    ch.basic_ack(delivery_tag=method.delivery_tag)

            channel.basic_consume(queue=queue_name, on_message_callback=callback)
            print("ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è§£æã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã—ã€åœ§ç¸®ç”Ÿãƒ‡ãƒ¼ã‚¿ã®å—ä¿¡å¾…æ©Ÿä¸­ã§ã™ã€‚")
            channel.start_consuming()
        except pika.exceptions.AMQPConnectionError:
            print("RabbitMQã¸ã®æ¥ç¶šã«å¤±æ•—... 5ç§’å¾Œã«å†è©¦è¡Œã—ã¾ã™ã€‚")
            time.sleep(5)
        except Exception as e:
            print(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ã§ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãŒåœæ­¢: {e}ã€‚5ç§’å¾Œã«å†èµ·å‹•ã—ã¾ã™...")
            time.sleep(5)

# --- API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ (Flask) ---
@app.route("/api/v1/users/<user_id>/analysis", methods=["GET"])
def get_analysis_results(user_id: str):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã«å¯¾å¿œã™ã‚‹æœ€æ–°ã®è§£æçµæœã‚’è¿”ã™ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€‚"""
    with analysis_lock:
        user_results = latest_analysis_results.get(user_id)
        if not user_results:
            return jsonify({"status": f"ãƒ¦ãƒ¼ã‚¶ãƒ¼({user_id})ã®è§£æçµæœã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“..."}), 202
        return jsonify(user_results)

# GunicornãŒã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãŸæ™‚ç‚¹ã§ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹ã—ã¾ã™ã€‚
# Gunicornã®ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒ1ã¤ã§ãªã„å ´åˆã€ã“ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã®æ•°ã ã‘èµ·å‹•ã—ã¾ã™ã€‚
threading.Thread(target=rabbitmq_consumer, daemon=True).start()
threading.Thread(target=analysis_worker, daemon=True).start()

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®é–‹å§‹ ---
if __name__ == "__main__":
    # ã“ã®éƒ¨åˆ†ã¯ã€'python main.py'ã¨ç›´æ¥å®Ÿè¡Œã—ãŸæ™‚(ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºæ™‚)ã«ã®ã¿ä½¿ã‚ã‚Œã¾ã™ã€‚
    print("Flask APIã‚µãƒ¼ãƒãƒ¼ã‚’ http://0.0.0.0:5002 ã§èµ·å‹•ã—ã¾ã™ï¼ˆé–‹ç™ºãƒ¢ãƒ¼ãƒ‰ï¼‰ã€‚")
    app.run(host="0.0.0.0", port=5002)