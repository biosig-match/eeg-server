x-common-logging: &common-logging
  driver: json-file
  options:
    max-size: '10m'
    max-file: '3'
x-postgres-env: &postgres-env
  POSTGRES_USER: ${POSTGRES_USER}
  POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
  POSTGRES_DB: ${POSTGRES_DB}
  POSTGRES_HOST: ${POSTGRES_HOST}
x-rabbitmq-env: &rabbitmq-env
  RABBITMQ_USER: ${RABBITMQ_USER}
  RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD}
  RABBITMQ_HOST: ${RABBITMQ_HOST}
x-object-storage-env: &object-storage-env
  OBJECT_STORAGE_ENDPOINT: ${OBJECT_STORAGE_ENDPOINT}
  OBJECT_STORAGE_PORT: ${OBJECT_STORAGE_PORT}
  OBJECT_STORAGE_ACCESS_KEY: ${OBJECT_STORAGE_ACCESS_KEY}
  OBJECT_STORAGE_SECRET_KEY: ${OBJECT_STORAGE_SECRET_KEY}
  OBJECT_STORAGE_USE_SSL: ${OBJECT_STORAGE_USE_SSL}
services:
  rabbitmq:
    image: rabbitmq:3.13-management-alpine
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD}
      - RABBITMQ_NODENAME=${RABBITMQ_NODENAME:-rabbit@rabbitmq}
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    networks:
      - eeg-network
    healthcheck:
      test: ['CMD', 'rabbitmq-diagnostics', 'check_running', '-q']
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 20s
  db:
    image: timescale/timescaledb-ha:pg16-ts2.14
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ../db/init.sql:/docker-entrypoint-initdb.d/init.sql
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    networks:
      - eeg-network
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB} -h localhost']
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 20s
  object-storage:
    image: chrislusf/seaweedfs:latest
    volumes:
      - object_storage_data:/data
    environment:
      - AWS_ACCESS_KEY_ID=${OBJECT_STORAGE_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${OBJECT_STORAGE_SECRET_KEY}
    command: >
      server -dir=/data -s3 -s3.port=${OBJECT_STORAGE_PORT} -s3.port.grpc=18333 -filer -filer.port=8888 -filer.port.grpc=18888 -ip=object-storage -ip.bind=0.0.0.0 -volume.port=8080 -volume.port.grpc=18080 -volume.max=0 -master.port=9333 -master.port.grpc=19333

    networks:
      - eeg-network
  object-storage-bootstrap:
    image: alpine:3.20
    depends_on:
      object-storage:
        condition: service_started
    environment:
      - OBJECT_STORAGE_ENDPOINT=${OBJECT_STORAGE_ENDPOINT}
      - OBJECT_STORAGE_PORT=${OBJECT_STORAGE_PORT}
      - OBJECT_STORAGE_USE_SSL=${OBJECT_STORAGE_USE_SSL}
      - OBJECT_STORAGE_ACCESS_KEY=${OBJECT_STORAGE_ACCESS_KEY}
      - OBJECT_STORAGE_SECRET_KEY=${OBJECT_STORAGE_SECRET_KEY}
      - OBJECT_STORAGE_RAW_DATA_BUCKET=${OBJECT_STORAGE_RAW_DATA_BUCKET}
      - OBJECT_STORAGE_MEDIA_BUCKET=${OBJECT_STORAGE_MEDIA_BUCKET}
      - OBJECT_STORAGE_BIDS_EXPORTS_BUCKET=${OBJECT_STORAGE_BIDS_EXPORTS_BUCKET}
      - OBJECT_STORAGE_ERP_MODELS_BUCKET=${OBJECT_STORAGE_ERP_MODELS_BUCKET}
    entrypoint:
      - /bin/sh
      - -c
      - |
        set -euo pipefail
        apk add --no-cache s3cmd
        SCHEME=$( [ "${OBJECT_STORAGE_USE_SSL}" = "true" ] && echo https || echo http )
        ENDPOINT="$${SCHEME}://${OBJECT_STORAGE_ENDPOINT}:${OBJECT_STORAGE_PORT}"
        USE_HTTPS=$( [ "${OBJECT_STORAGE_USE_SSL}" = "true" ] && echo True || echo False )
        printf '[default]\n' > /tmp/s3cfg
        printf 'access_key = %s\n' "${OBJECT_STORAGE_ACCESS_KEY}" >> /tmp/s3cfg
        printf 'secret_key = %s\n' "${OBJECT_STORAGE_SECRET_KEY}" >> /tmp/s3cfg
        printf 'host_base = %s:%s\n' "${OBJECT_STORAGE_ENDPOINT}" "${OBJECT_STORAGE_PORT}" >> /tmp/s3cfg
        printf 'host_bucket = %s:%s\n' "${OBJECT_STORAGE_ENDPOINT}" "${OBJECT_STORAGE_PORT}" >> /tmp/s3cfg
        printf 'use_https = %s\n' "$${USE_HTTPS}" >> /tmp/s3cfg
        printf 'check_ssl_certificate = False\n' >> /tmp/s3cfg
        printf 'check_ssl_hostname = False\n' >> /tmp/s3cfg
        printf 'signature_v2 = False\n' >> /tmp/s3cfg
        echo "Waiting for object storage endpoint $${ENDPOINT}..."
        MAX_RETRIES=30
        RETRY_COUNT=0
        until s3cmd --config=/tmp/s3cfg ls >/dev/null 2>&1; do
          RETRY_COUNT=$$((RETRY_COUNT + 1))
          if [ $${RETRY_COUNT} -ge $${MAX_RETRIES} ]; then
            echo "❌ ERROR: Object storage did not become ready after $${MAX_RETRIES} attempts (60 seconds). Exiting."
            exit 1
          fi
          sleep 2
        done
        echo "✅ Object storage endpoint is ready."
        ensure_bucket() {
          BUCKET="$1"
          if [ -z "$${BUCKET}" ]; then
            return 0
          fi
          if s3cmd --config=/tmp/s3cfg ls "s3://$${BUCKET}" >/dev/null 2>&1; then
            echo "✅ Bucket $${BUCKET} already exists."
          else
            s3cmd --config=/tmp/s3cfg mb "s3://$${BUCKET}"
            echo "✅ Bucket $${BUCKET} created."
          fi
        }
        ensure_bucket "${OBJECT_STORAGE_RAW_DATA_BUCKET}"
        ensure_bucket "${OBJECT_STORAGE_MEDIA_BUCKET}"
        ensure_bucket "${OBJECT_STORAGE_BIDS_EXPORTS_BUCKET}"
        ensure_bucket "${OBJECT_STORAGE_ERP_MODELS_BUCKET}"
        echo "✅ Bucket bootstrap completed."
    networks:
      - eeg-network
  collector:
    build:
      context: ..
      dockerfile: docker/Dockerfile.bun
      args:
        SERVICE_NAME: collector
    restart: unless-stopped
    depends_on:
      rabbitmq:
        condition: service_healthy
    environment:
      !!merge <<: *rabbitmq-env
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@${RABBITMQ_HOST}
    networks:
      - eeg-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:3000/health']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    logging: *common-logging
  processor:
    build:
      context: ..
      dockerfile: docker/Dockerfile.bun
      args:
        SERVICE_NAME: processor
    restart: unless-stopped
    depends_on:
      object-storage-bootstrap:
        condition: service_completed_successfully
      rabbitmq:
        condition: service_healthy
      db:
        condition: service_healthy
    environment:
      !!merge <<: [*rabbitmq-env, *postgres-env, *object-storage-env]
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@${RABBITMQ_HOST}
      DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/${POSTGRES_DB}
      OBJECT_STORAGE_RAW_DATA_BUCKET: ${OBJECT_STORAGE_RAW_DATA_BUCKET}
    networks:
      - eeg-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:3010/health']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
    logging: *common-logging
  media_processor:
    build:
      context: ..
      dockerfile: docker/Dockerfile.bun
      args:
        SERVICE_NAME: media_processor
    restart: unless-stopped
    depends_on:
      object-storage-bootstrap:
        condition: service_completed_successfully
      rabbitmq:
        condition: service_healthy
      db:
        condition: service_healthy
    environment:
      !!merge <<: [*rabbitmq-env, *postgres-env, *object-storage-env]
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@${RABBITMQ_HOST}
      DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/${POSTGRES_DB}
      OBJECT_STORAGE_MEDIA_BUCKET: ${OBJECT_STORAGE_MEDIA_BUCKET}
    networks:
      - eeg-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:3020/health']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
    logging: *common-logging
  realtime_analyzer:
    build:
      context: ..
      dockerfile: docker/Dockerfile.python
      args:
        SERVICE_NAME: realtime_analyzer
    restart: unless-stopped
    command: gunicorn --bind 0.0.0.0:5002 --workers 1 --log-level debug 'src.main:app'
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - eeg-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:5002/health']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
    logging: *common-logging
  observability_dashboard:
    build:
      context: ..
      dockerfile: docker/Dockerfile.bun
      args:
        SERVICE_NAME: observability_dashboard
    restart: unless-stopped
    depends_on:
      rabbitmq:
        condition: service_healthy
      db:
        condition: service_healthy
      object-storage:
        condition: service_started
    environment:
      !!merge <<: [*postgres-env, *rabbitmq-env, *object-storage-env]
      RABBITMQ_MGMT_PORT: ${RABBITMQ_MGMT_PORT}
      RAW_DATA_EXCHANGE: ${RAW_DATA_EXCHANGE}
      PROCESSING_QUEUE: ${PROCESSING_QUEUE}
      MEDIA_PROCESSING_QUEUE: ${MEDIA_PROCESSING_QUEUE}
      DATA_LINKER_QUEUE: ${DATA_LINKER_QUEUE}
      EVENT_CORRECTION_QUEUE: ${EVENT_CORRECTION_QUEUE}
      STIMULUS_ASSET_QUEUE: ${STIMULUS_ASSET_QUEUE}
      OBJECT_STORAGE_RAW_DATA_BUCKET: ${OBJECT_STORAGE_RAW_DATA_BUCKET}
      OBJECT_STORAGE_MEDIA_BUCKET: ${OBJECT_STORAGE_MEDIA_BUCKET}
      OBJECT_STORAGE_BIDS_EXPORTS_BUCKET: ${OBJECT_STORAGE_BIDS_EXPORTS_BUCKET}
      DASHBOARD_REFRESH_INTERVAL_MS: ${OBSERVABILITY_DASHBOARD_REFRESH_MS:-4000}
      OBSERVABILITY_BASIC_USER: ${OBSERVABILITY_BASIC_USER:-observer}
      OBSERVABILITY_BASIC_PASSWORD: ${OBSERVABILITY_BASIC_PASSWORD:-changeme}
      OBSERVABILITY_BASIC_REALM: ${OBSERVABILITY_BASIC_REALM:-Observability Dashboard}
    networks:
      - eeg-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:9000/health']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 384M
    logging: *common-logging
  ingress:
    build: ../nginx
    restart: unless-stopped
    depends_on:
      collector:
        condition: service_started
      realtime_analyzer:
        condition: service_started
      session_manager:
        condition: service_started
      auth_manager:
        condition: service_started
      erp_neuro_marketing:
        condition: service_started
      bids_exporter:
        condition: service_started
    networks:
      - eeg-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    logging: *common-logging
  session_manager:
    build:
      context: ..
      dockerfile: docker/Dockerfile.bun
      args:
        SERVICE_NAME: session_manager
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      auth_manager:
        condition: service_started
    environment:
      !!merge <<: [*postgres-env, *rabbitmq-env, *object-storage-env]
      PORT: 3000
      OBJECT_STORAGE_MEDIA_BUCKET: ${OBJECT_STORAGE_MEDIA_BUCKET}
      DATA_LINKER_QUEUE: ${DATA_LINKER_QUEUE}
      STIMULUS_ASSET_QUEUE: ${STIMULUS_ASSET_QUEUE}
      AUTH_MANAGER_URL: ${AUTH_MANAGER_URL}
      # BIDS ExporterサービスのURLを環境変数として渡す
      BIDS_EXPORTER_URL: ${BIDS_EXPORTER_URL}
    networks:
      - eeg-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:3000/health']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 384M
    logging: *common-logging
  stimulus_asset_processor:
    build:
      context: ..
      dockerfile: docker/Dockerfile.bun
      args:
        SERVICE_NAME: stimulus_asset_processor
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      object-storage-bootstrap:
        condition: service_completed_successfully
    environment:
      !!merge <<: [*postgres-env, *rabbitmq-env, *object-storage-env]
      OBJECT_STORAGE_MEDIA_BUCKET: ${OBJECT_STORAGE_MEDIA_BUCKET}
      STIMULUS_ASSET_QUEUE: ${STIMULUS_ASSET_QUEUE}
    networks:
      - eeg-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:3050/health']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 384M
    logging: *common-logging
  auth_manager:
    build:
      context: ..
      dockerfile: docker/Dockerfile.bun
      args:
        SERVICE_NAME: auth_manager
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
    environment:
      !!merge <<: *postgres-env
      PORT: 3000
    networks:
      - eeg-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:3000/health']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.3'
          memory: 256M
    logging: *common-logging
  data_linker:
    build:
      context: ..
      dockerfile: docker/Dockerfile.bun
      args:
        SERVICE_NAME: data_linker
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    environment:
      !!merge <<: [*postgres-env, *rabbitmq-env]
      DATA_LINKER_QUEUE: ${DATA_LINKER_QUEUE}
      EVENT_CORRECTION_QUEUE: ${EVENT_CORRECTION_QUEUE}
    networks:
      - eeg-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:3030/health']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 384M
    logging: *common-logging
  event_corrector:
    build:
      context: ..
      dockerfile: docker/Dockerfile.bun
      args:
        SERVICE_NAME: event_corrector
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      object-storage-bootstrap:
        condition: service_completed_successfully
    environment:
      !!merge <<: [*postgres-env, *rabbitmq-env, *object-storage-env]
      EVENT_CORRECTION_QUEUE: ${EVENT_CORRECTION_QUEUE}
      OBJECT_STORAGE_RAW_DATA_BUCKET: ${OBJECT_STORAGE_RAW_DATA_BUCKET}
      SAMPLE_RATE: 256
    networks:
      - eeg-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:3040/health']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 384M
    logging: *common-logging
  bids_exporter:
    build:
      context: ..
      dockerfile: docker/Dockerfile.python
      args:
        SERVICE_NAME: bids_exporter
    restart: unless-stopped
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000
    volumes:
      - bids_exports_volume:/export_data
    depends_on:
      db:
        condition: service_healthy
      object-storage-bootstrap:
        condition: service_completed_successfully
    environment:
      !!merge <<: [*postgres-env, *object-storage-env]
      DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/${POSTGRES_DB}
      OBJECT_STORAGE_RAW_DATA_BUCKET: ${OBJECT_STORAGE_RAW_DATA_BUCKET}
      OBJECT_STORAGE_MEDIA_BUCKET: ${OBJECT_STORAGE_MEDIA_BUCKET}
      OBJECT_STORAGE_BIDS_EXPORTS_BUCKET: ${OBJECT_STORAGE_BIDS_EXPORTS_BUCKET}
      EXPORT_DATA_PATH: /export_data
    networks:
      - eeg-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:8000/health']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    logging: *common-logging
  erp_neuro_marketing:
    build:
      context: ..
      dockerfile: docker/Dockerfile.python
      args:
        SERVICE_NAME: erp_neuro_marketing
    restart: unless-stopped
    command: uvicorn src.main:app --host 0.0.0.0 --port 8001
    depends_on:
      db:
        condition: service_healthy
      auth_manager:
        condition: service_started
      bids_exporter:
        condition: service_started
    volumes:
      - bids_exports_volume:/export_data
    environment:
      !!merge <<: *postgres-env
      DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/${POSTGRES_DB}
      BIDS_EXPORTER_URL: http://bids_exporter:8000
      AUTH_MANAGER_URL: http://auth_manager:3000
      SHARED_VOLUME_PATH: /export_data
      GEMINI_API_KEY: ${GEMINI_API_KEY}
    networks:
      - eeg-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:8001/health']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 768M
    logging: *common-logging
volumes:
  pg_data:
  object_storage_data:
  bids_exports_volume:
  rabbitmq_data:
networks:
  eeg-network:
    driver: bridge
